<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/Neural_Networks_Learning_Guide.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Neural_Networks_Learning_Guide.ipynb" />
              <option name="originalContent" value="#%%&#10;" />
              <option name="updatedContent" value="#%%&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Neural_Networks_Step_by_Step.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Neural_Networks_Step_by_Step.ipynb" />
              <option name="originalContent" value="#%%&#10;# Neural Networks Step by Step&#10;&#10;# Step 1: Introduction to Neural Networks&#10;&#10;# A neural network is a type of machine learning model inspired by the human brain. It is made up of layers of interconnected nodes (neurons), which can learn to recognize patterns in data.&#10;&#10;# Why use neural networks?&#10;# - They can learn complex relationships in data.&#10;# - They are used in image recognition, language translation, and more.&#10;&#10;# Key Terms&#10;# - Neuron: A single unit in the network that processes input.&#10;# - Layer: A group of neurons. Networks have input, hidden, and output layers.&#10;# - Weights: Parameters that adjust as the network learns.&#10;# - Activation Function: Decides if a neuron should be activated.&#10;&#10;# ---&#10;&#10;# Step 2: The Perceptron (the simplest neural network)&#10;# Let's build a perceptron to understand the basics.&#10;&#10;import numpy as np&#10;&#10;# Perceptron function&#10;def perceptron(x, w, b):&#10;    z = np.dot(x, w) + b&#10;    return 1 if z &gt; 0 else 0&#10;&#10;# Example inputs&#10;x = np.array([1, 0])  # Input features&#10;w = np.array([0.5, -0.6])  # Weights&#10;b = 0.1  # Bias&#10;&#10;output = perceptron(x, w, b)&#10;print(f'Perceptron output: {output}')&#10;&#10;# ---&#10;&#10;# Step 3: Building a Simple Neural Network&#10;# Let's build a neural network with one hidden layer.&#10;&#10;def sigmoid(x):&#10;    return 1 / (1 + np.exp(-x))&#10;&#10;# Input&#10;X = np.array([[0,0],[0,1],[1,0],[1,1]])&#10;# Output (XOR problem)&#10;y = np.array([[0],[1],[1],[0]])&#10;&#10;# Initialize weights&#10;np.random.seed(42)&#10;W1 = np.random.randn(2, 2)&#10;B1 = np.zeros((1, 2))&#10;W2 = np.random.randn(2, 1)&#10;B2 = np.zeros((1, 1))&#10;&#10;# Forward pass&#10;def forward(X):&#10;    Z1 = np.dot(X, W1) + B1&#10;    A1 = sigmoid(Z1)&#10;    Z2 = np.dot(A1, W2) + B2&#10;    A2 = sigmoid(Z2)&#10;    return A2&#10;&#10;output = forward(X)&#10;print('Network output:\n', output)&#10;&#10;# ---&#10;&#10;# Step 4: Training a Neural Network&#10;# Training means adjusting weights to minimize error. This is done using backpropagation and a loss function.&#10;&#10;def mse(y_true, y_pred):&#10;    return ((y_true - y_pred) ** 2).mean()&#10;&#10;# Example loss&#10;y_pred = forward(X)&#10;loss = mse(y, y_pred)&#10;print(f'Loss: {loss}')&#10;&#10;#%%&#10;# Step 5: Using a Framework (Keras)&#10;# Let's use Keras to build a neural network easily.&#10;&#10;# Build and train the model, then save it&#10;import tensorflow as tf&#10;from tensorflow import keras&#10;from tensorflow.keras import layers&#10;&#10;model = keras.Sequential([&#10;    layers.Dense(4, activation='tanh', input_shape=(2,)),&#10;    layers.Dense(1, activation='sigmoid')&#10;])&#10;model.compile(optimizer='adam', loss='binary_crossentropy')&#10;&#10;X = np.array([&#10;    [0,0],[0,1],[1,0],[1,1],&#10;    [0,0],[0,1],[1,0],[1,1]  # duplicate for more data&#10;])&#10;y = np.array([&#10;    [0],[1],[1],[0],&#10;    [0],[1],[1],[0]&#10;])&#10;&#10;model.fit(X, y, epochs=1000, verbose=0)&#10;model.save('xor_model.keras')&#10;print('Predictions:', model.predict(X))&#10;#%%&#10;# Step 6: Load and use the trained model (no retraining needed)&#10;from tensorflow import keras&#10;loaded_model = keras.models.load_model('xor_model.keras')&#10;print('Loaded model predictions:', loaded_model.predict(X))&#10;&#10;&#10;&#10;" />
              <option name="updatedContent" value="#%%&#10;# Neural Networks Step by Step&#10;&#10;# Step 1: Introduction to Neural Networks&#10;&#10;# A neural network is a type of machine learning model inspired by the human brain. It is made up of layers of interconnected nodes (neurons), which can learn to recognize patterns in data.&#10;&#10;# Why use neural networks?&#10;# - They can learn complex relationships in data.&#10;# - They are used in image recognition, language translation, and more.&#10;&#10;# Key Terms&#10;# - Neuron: A single unit in the network that processes input.&#10;# - Layer: A group of neurons. Networks have input, hidden, and output layers.&#10;# - Weights: Parameters that adjust as the network learns.&#10;# - Activation Function: Decides if a neuron should be activated.&#10;&#10;# ---&#10;&#10;# Step 2: The Perceptron (the simplest neural network)&#10;# Let's build a perceptron to understand the basics.&#10;&#10;import numpy as np&#10;&#10;# Perceptron function&#10;def perceptron(x, w, b):&#10;    z = np.dot(x, w) + b&#10;    return 1 if z &gt; 0 else 0&#10;&#10;# Example inputs&#10;x = np.array([1, 0])  # Input features&#10;w = np.array([0.5, -0.6])  # Weights&#10;b = 0.1  # Bias&#10;&#10;output = perceptron(x, w, b)&#10;print(f'Perceptron output: {output}')&#10;&#10;# ---&#10;&#10;# Step 3: Building a Simple Neural Network&#10;# Let's build a neural network with one hidden layer.&#10;&#10;def sigmoid(x):&#10;    return 1 / (1 + np.exp(-x))&#10;&#10;# Input&#10;X = np.array([[0,0],[0,1],[1,0],[1,1]])&#10;# Output (XOR problem)&#10;y = np.array([[0],[1],[1],[0]])&#10;&#10;# Initialize weights&#10;np.random.seed(42)&#10;W1 = np.random.randn(2, 2)&#10;B1 = np.zeros((1, 2))&#10;W2 = np.random.randn(2, 1)&#10;B2 = np.zeros((1, 1))&#10;&#10;# Forward pass&#10;def forward(X):&#10;    Z1 = np.dot(X, W1) + B1&#10;    A1 = sigmoid(Z1)&#10;    Z2 = np.dot(A1, W2) + B2&#10;    A2 = sigmoid(Z2)&#10;    return A2&#10;&#10;output = forward(X)&#10;print('Network output:\n', output)&#10;&#10;# ---&#10;&#10;# Step 4: Training a Neural Network&#10;# Training means adjusting weights to minimize error. This is done using backpropagation and a loss function.&#10;&#10;def mse(y_true, y_pred):&#10;    return ((y_true - y_pred) ** 2).mean()&#10;&#10;# Example loss&#10;y_pred = forward(X)&#10;loss = mse(y, y_pred)&#10;print(f'Loss: {loss}')&#10;&#10;#%%&#10;# Step 5: Using a Framework (Keras)&#10;# Let's use Keras to build a neural network easily.&#10;&#10;# Build and train the model, then save it&#10;import tensorflow as tf&#10;from tensorflow import keras&#10;from tensorflow.keras import layers&#10;&#10;model = keras.Sequential([&#10;    layers.Dense(4, activation='tanh', input_shape=(2,)),&#10;    layers.Dense(1, activation='sigmoid')&#10;])&#10;model.compile(optimizer='adam', loss='binary_crossentropy')&#10;&#10;X = np.array([&#10;    [0,0],[0,1],[1,0],[1,1],&#10;    [0,0],[0,1],[1,0],[1,1]  # duplicate for more data&#10;])&#10;y = np.array([&#10;    [0],[1],[1],[0],&#10;    [0],[1],[1],[0]&#10;])&#10;&#10;model.fit(X, y, epochs=1000, verbose=0)&#10;model.save('xor_model.keras')&#10;print('Predictions:', model.predict(X))&#10;#%%&#10;# Step 6: Load and use the trained model (no retraining needed)&#10;from tensorflow import keras&#10;loaded_model = keras.models.load_model('xor_model.keras')&#10;print('Loaded model predictions:', loaded_model.predict(X))&#10;#%%&#10;# Step 1: Generate a small synthetic fraud detection dataset for demonstration&#10;import numpy as np&#10;import pandas as pd&#10;&#10;np.random.seed(42)&#10;&#10;# Generate 1000 samples&#10;n_samples = 1000&#10;# Features: amount, transaction_time, is_foreign, is_high_risk_country&#10;amount = np.random.exponential(scale=100, size=n_samples)&#10;transaction_time = np.random.randint(0, 24, size=n_samples)  # hour of day&#10;is_foreign = np.random.binomial(1, 0.1, size=n_samples)  # 10% foreign&#10;is_high_risk_country = np.random.binomial(1, 0.05, size=n_samples)  # 5% high risk&#10;&#10;# Generate labels: fraud is more likely for high amount, foreign, high risk country, odd hours&#10;fraud = (&#10;    (amount &gt; 200).astype(int) +&#10;    (is_foreign == 1).astype(int) +&#10;    (is_high_risk_country == 1).astype(int) +&#10;    ((transaction_time &lt; 6) | (transaction_time &gt; 22)).astype(int)&#10;)&#10;# If sum of risk factors &gt;= 2, label as fraud&#10;labels = (fraud &gt;= 2).astype(int)&#10;&#10;# Create DataFrame&#10;fraud_df = pd.DataFrame({&#10;    'amount': amount,&#10;    'transaction_time': transaction_time,&#10;    'is_foreign': is_foreign,&#10;    'is_high_risk_country': is_high_risk_country,&#10;    'fraud': labels&#10;})&#10;&#10;print('Sample of synthetic fraud detection data:')&#10;display(fraud_df.head())&#10;print('Fraud distribution:')&#10;print(fraud_df[&quot;fraud&quot;].value_counts())" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Neural_Networks_Step_by_Step.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Neural_Networks_Step_by_Step.py" />
              <option name="updatedContent" value="# Neural Networks Step by Step&#10;&#10;# Step 1: Introduction to Neural Networks&#10;&#10;# A neural network is a type of machine learning model inspired by the human brain. It is made up of layers of interconnected nodes (neurons), which can learn to recognize patterns in data.&#10;&#10;# Why use neural networks?&#10;# - They can learn complex relationships in data.&#10;# - They are used in image recognition, language translation, and more.&#10;&#10;# Key Terms&#10;# - Neuron: A single unit in the network that processes input.&#10;# - Layer: A group of neurons. Networks have input, hidden, and output layers.&#10;# - Weights: Parameters that adjust as the network learns.&#10;# - Activation Function: Decides if a neuron should be activated.&#10;&#10;# ---&#10;&#10;# Step 2: The Perceptron (the simplest neural network)&#10;# Let's build a perceptron to understand the basics.&#10;&#10;import numpy as np&#10;&#10;# Perceptron function&#10;def perceptron(x, w, b):&#10;    z = np.dot(x, w) + b&#10;    return 1 if z &gt; 0 else 0&#10;&#10;# Example inputs&#10;x = np.array([1, 0])  # Input features&#10;w = np.array([0.5, -0.6])  # Weights&#10;b = 0.1  # Bias&#10;&#10;output = perceptron(x, w, b)&#10;print(f'Perceptron output: {output}')&#10;&#10;# ---&#10;&#10;# Step 3: Building a Simple Neural Network&#10;# Let's build a neural network with one hidden layer.&#10;&#10;def sigmoid(x):&#10;    return 1 / (1 + np.exp(-x))&#10;&#10;# Input&#10;X = np.array([[0,0],[0,1],[1,0],[1,1]])&#10;# Output (XOR problem)&#10;y = np.array([[0],[1],[1],[0]])&#10;&#10;# Initialize weights&#10;np.random.seed(42)&#10;W1 = np.random.randn(2, 2)&#10;B1 = np.zeros((1, 2))&#10;W2 = np.random.randn(2, 1)&#10;B2 = np.zeros((1, 1))&#10;&#10;# Forward pass&#10;def forward(X):&#10;    Z1 = np.dot(X, W1) + B1&#10;    A1 = sigmoid(Z1)&#10;    Z2 = np.dot(A1, W2) + B2&#10;    A2 = sigmoid(Z2)&#10;    return A2&#10;&#10;output = forward(X)&#10;print('Network output:\n', output)&#10;&#10;# ---&#10;&#10;# Step 4: Training a Neural Network&#10;# Training means adjusting weights to minimize error. This is done using backpropagation and a loss function.&#10;&#10;def mse(y_true, y_pred):&#10;    return ((y_true - y_pred) ** 2).mean()&#10;&#10;# Example loss&#10;y_pred = forward(X)&#10;loss = mse(y, y_pred)&#10;print(f'Loss: {loss}')&#10;&#10;# ---&#10;&#10;# Step 5: Using a Framework (Keras)&#10;# Let's use Keras to build a neural network easily.&#10;&#10;import tensorflow as tf&#10;from tensorflow import keras&#10;from tensorflow.keras import layers&#10;&#10;# Build model&#10;model = keras.Sequential([&#10;    layers.Dense(2, activation='sigmoid', input_shape=(2,)),&#10;    layers.Dense(1, activation='sigmoid')&#10;])&#10;&#10;model.compile(optimizer='adam', loss='mse')&#10;model.fit(X, y, epochs=100, verbose=0)&#10;&#10;print('Predictions:', model.predict(X))&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/README.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/README.md" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/data_generator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/data_generator.py" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/fraud-detection/Fraud_Detection.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/fraud-detection/Fraud_Detection.ipynb" />
              <option name="originalContent" value="#%%&#10;# Step 1: Generate a small synthetic fraud detection dataset for demonstration&#10;import numpy as np&#10;import pandas as pd&#10;&#10;np.random.seed(42)&#10;&#10;# Generate 1000 samples&#10;n_samples = 1000&#10;# Features: amount, transaction_time, is_foreign, is_high_risk_country&#10;amount = np.random.exponential(scale=100, size=n_samples)&#10;transaction_time = np.random.randint(0, 24, size=n_samples)  # hour of day&#10;is_foreign = np.random.binomial(1, 0.1, size=n_samples)  # 10% foreign&#10;is_high_risk_country = np.random.binomial(1, 0.05, size=n_samples)  # 5% high risk&#10;&#10;# Generate labels: fraud is more likely for high amount, foreign, high risk country, odd hours&#10;fraud = (&#10;        (amount &gt; 200).astype(int) +&#10;        (is_foreign == 1).astype(int) +&#10;        (is_high_risk_country == 1).astype(int) +&#10;        ((transaction_time &lt; 6) | (transaction_time &gt; 22)).astype(int)&#10;)&#10;# If sum of risk factors &gt;= 2, label as fraud&#10;labels = (fraud &gt;= 2).astype(int)&#10;&#10;# Create DataFrame&#10;fraud_df = pd.DataFrame({&#10;    'amount': amount,&#10;    'transaction_time': transaction_time,&#10;    'is_foreign': is_foreign,&#10;    'is_high_risk_country': is_high_risk_country,&#10;    'fraud': labels&#10;})&#10;&#10;print('Sample of synthetic fraud detection data:')&#10;display(fraud_df.head())&#10;print('Fraud distribution:')&#10;print(fraud_df[&quot;fraud&quot;].value_counts())&#10;&#10;# Save the generated synthetic fraud detection DataFrame to a CSV file for later use.&#10;fraud_df.to_csv('synthetic_fraud_data.csv', index=False)&#10;print('Data saved to synthetic_fraud_data.csv')&#10;&#10;#%%&#10;# Step 2: Read the synthetic fraud detection data from file&#10;import pandas as pd&#10;fraud_df = pd.read_csv('synthetic_fraud_data.csv')&#10;print('Loaded data sample:')&#10;display(fraud_df.head())&#10;print('Fraud distribution:')&#10;print(fraud_df['fraud'].value_counts())&#10;&#10;#%%&#10;# Step 3: Exploratory Data Analysis (EDA)&#10;import matplotlib.pyplot as plt&#10;&#10;# 1. Check for missing values&#10;print('Missing values in each column:')&#10;print(fraud_df.isnull().sum())&#10;&#10;# 2. Summary statistics&#10;print('\nSummary statistics:')&#10;print(fraud_df.describe())&#10;&#10;# 3. Visualize feature distributions&#10;fig, axs = plt.subplots(2, 2, figsize=(12, 8))&#10;axs[0, 0].hist(fraud_df['amount'], bins=30, color='skyblue')&#10;axs[0, 0].set_title('Amount Distribution')&#10;axs[0, 1].hist(fraud_df['transaction_time'], bins=24, color='orange')&#10;axs[0, 1].set_title('Transaction Time Distribution')&#10;axs[1, 0].bar(['No', 'Yes'], fraud_df['is_foreign'].value_counts().sort_index(), color='green')&#10;axs[1, 0].set_title('Is Foreign')&#10;axs[1, 1].bar(['No', 'Yes'], fraud_df['is_high_risk_country'].value_counts().sort_index(), color='red')&#10;axs[1, 1].set_title('Is High Risk Country')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;# 4. Check class balance&#10;print('\nFraud class balance:')&#10;print(fraud_df['fraud'].value_counts(normalize=True))&#10;&#10;#%%&#10;# Step 4: Data Preprocessing (train-test split and scaling)&#10;from sklearn.model_selection import train_test_split&#10;from sklearn.preprocessing import StandardScaler&#10;&#10;# 1. Split features and target&#10;y = fraud_df['fraud']&#10;X = fraud_df.drop('fraud', axis=1)&#10;&#10;# 2. Train-test split (80% train, 20% test)&#10;X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)&#10;&#10;# 3. Scale numerical features&#10;scaler = StandardScaler()&#10;&#10;X_train[['amount', 'transaction_time']] = scaler.fit_transform(X_train[['amount', 'transaction_time']])&#10;X_test[['amount', 'transaction_time']] = scaler.transform(X_test[['amount', 'transaction_time']])&#10;&#10;# 4. Show shapes&#10;print(f'Training set shape: {X_train.shape}, {y_train.shape}')&#10;print(f'Test set shape: {X_test.shape}, {y_test.shape}')&#10;print('Sample of scaled training data:')&#10;display(X_train.head())&#10;&#10;# Save train and test data for later use&#10;X_train.to_csv('X_train.csv', index=False)&#10;X_test.to_csv('X_test.csv', index=False)&#10;y_train.to_csv('y_train.csv', index=False)&#10;y_test.to_csv('y_test.csv', index=False)&#10;print('Train and test data saved as X_train.csv, X_test.csv, y_train.csv, y_test.csv')&#10;&#10;#%%&#10;# Step 5: Train and evaluate a Logistic Regression model for fraud detection&#10;from sklearn.linear_model import LogisticRegression&#10;from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score&#10;import pandas as pd&#10;&#10;# Load train and test data (in case running this cell independently)&#10;X_train = pd.read_csv('X_train.csv')&#10;X_test = pd.read_csv('X_test.csv')&#10;y_train = pd.read_csv('y_train.csv').values.ravel()&#10;y_test = pd.read_csv('y_test.csv').values.ravel()&#10;&#10;# Train logistic regression model&#10;logreg = LogisticRegression(random_state=42)&#10;logreg.fit(X_train, y_train)&#10;&#10;# Predict on test set&#10;y_pred = logreg.predict(X_test)&#10;y_proba = logreg.predict_proba(X_test)[:, 1]&#10;&#10;# Evaluation&#10;print('Confusion Matrix:')&#10;print(confusion_matrix(y_test, y_pred))&#10;print('\nClassification Report:')&#10;print(classification_report(y_test, y_pred, digits=3))&#10;print(f'ROC AUC Score: {roc_auc_score(y_test, y_proba):.3f}')&#10;" />
              <option name="updatedContent" value="#%%&#10;# Step 1: Generate a small synthetic fraud detection dataset for demonstration&#10;import numpy as np&#10;import pandas as pd&#10;&#10;np.random.seed(42)&#10;&#10;# Generate 1000 samples&#10;n_samples = 1000&#10;# Features: amount, transaction_time, is_foreign, is_high_risk_country&#10;amount = np.random.exponential(scale=100, size=n_samples)&#10;transaction_time = np.random.randint(0, 24, size=n_samples)  # hour of day&#10;is_foreign = np.random.binomial(1, 0.1, size=n_samples)  # 10% foreign&#10;is_high_risk_country = np.random.binomial(1, 0.05, size=n_samples)  # 5% high risk&#10;&#10;# Generate labels: fraud is more likely for high amount, foreign, high risk country, odd hours&#10;fraud = (&#10;        (amount &gt; 200).astype(int) +&#10;        (is_foreign == 1).astype(int) +&#10;        (is_high_risk_country == 1).astype(int) +&#10;        ((transaction_time &lt; 6) | (transaction_time &gt; 22)).astype(int)&#10;)&#10;# If sum of risk factors &gt;= 2, label as fraud&#10;labels = (fraud &gt;= 2).astype(int)&#10;&#10;# Create DataFrame&#10;fraud_df = pd.DataFrame({&#10;    'amount': amount,&#10;    'transaction_time': transaction_time,&#10;    'is_foreign': is_foreign,&#10;    'is_high_risk_country': is_high_risk_country,&#10;    'fraud': labels&#10;})&#10;&#10;print('Sample of synthetic fraud detection data:')&#10;display(fraud_df.head())&#10;print('Fraud distribution:')&#10;print(fraud_df[&quot;fraud&quot;].value_counts())&#10;&#10;# Save the generated synthetic fraud detection DataFrame to a CSV file for later use.&#10;fraud_df.to_csv('synthetic_fraud_data.csv', index=False)&#10;print('Data saved to synthetic_fraud_data.csv')&#10;&#10;#%%&#10;# Step 2: Read the synthetic fraud detection data from file&#10;import pandas as pd&#10;fraud_df = pd.read_csv('synthetic_fraud_data.csv')&#10;print('Loaded data sample:')&#10;display(fraud_df.head())&#10;print('Fraud distribution:')&#10;print(fraud_df['fraud'].value_counts())&#10;&#10;#%%&#10;# Step 3: Exploratory Data Analysis (EDA)&#10;import matplotlib.pyplot as plt&#10;&#10;# 1. Check for missing values&#10;print('Missing values in each column:')&#10;print(fraud_df.isnull().sum())&#10;&#10;# 2. Summary statistics&#10;print('\nSummary statistics:')&#10;print(fraud_df.describe())&#10;&#10;# 3. Visualize feature distributions&#10;fig, axs = plt.subplots(2, 2, figsize=(12, 8))&#10;axs[0, 0].hist(fraud_df['amount'], bins=30, color='skyblue')&#10;axs[0, 0].set_title('Amount Distribution')&#10;axs[0, 1].hist(fraud_df['transaction_time'], bins=24, color='orange')&#10;axs[0, 1].set_title('Transaction Time Distribution')&#10;axs[1, 0].bar(['No', 'Yes'], fraud_df['is_foreign'].value_counts().sort_index(), color='green')&#10;axs[1, 0].set_title('Is Foreign')&#10;axs[1, 1].bar(['No', 'Yes'], fraud_df['is_high_risk_country'].value_counts().sort_index(), color='red')&#10;axs[1, 1].set_title('Is High Risk Country')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;# 4. Check class balance&#10;print('\nFraud class balance:')&#10;print(fraud_df['fraud'].value_counts(normalize=True))&#10;&#10;#%%&#10;# Step 4: Data Preprocessing (train-test split and scaling)&#10;from sklearn.model_selection import train_test_split&#10;from sklearn.preprocessing import StandardScaler&#10;&#10;# 1. Split features and target&#10;y = fraud_df['fraud']&#10;X = fraud_df.drop('fraud', axis=1)&#10;&#10;# 2. Train-test split (80% train, 20% test)&#10;X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)&#10;&#10;# 3. Scale numerical features&#10;scaler = StandardScaler()&#10;&#10;X_train[['amount', 'transaction_time']] = scaler.fit_transform(X_train[['amount', 'transaction_time']])&#10;X_test[['amount', 'transaction_time']] = scaler.transform(X_test[['amount', 'transaction_time']])&#10;&#10;# 4. Show shapes&#10;print(f'Training set shape: {X_train.shape}, {y_train.shape}')&#10;print(f'Test set shape: {X_test.shape}, {y_test.shape}')&#10;print('Sample of scaled training data:')&#10;display(X_train.head())&#10;&#10;# Save train and test data for later use&#10;X_train.to_csv('X_train.csv', index=False)&#10;X_test.to_csv('X_test.csv', index=False)&#10;y_train.to_csv('y_train.csv', index=False)&#10;y_test.to_csv('y_test.csv', index=False)&#10;print('Train and test data saved as X_train.csv, X_test.csv, y_train.csv, y_test.csv')&#10;&#10;#%%&#10;# Step 5: Train and evaluate a Logistic Regression model for fraud detection&#10;from sklearn.linear_model import LogisticRegression&#10;from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score&#10;import pandas as pd&#10;&#10;# Load train and test data (in case running this cell independently)&#10;X_train = pd.read_csv('X_train.csv')&#10;X_test = pd.read_csv('X_test.csv')&#10;y_train = pd.read_csv('y_train.csv').values.ravel()&#10;y_test = pd.read_csv('y_test.csv').values.ravel()&#10;&#10;# Train logistic regression model&#10;logreg = LogisticRegression(random_state=42)&#10;logreg.fit(X_train, y_train)&#10;&#10;# Predict on test set&#10;y_pred = logreg.predict(X_test)&#10;y_proba = logreg.predict_proba(X_test)[:, 1]&#10;&#10;# Evaluation&#10;print('Confusion Matrix:')&#10;print(confusion_matrix(y_test, y_pred))&#10;print('\nClassification Report:')&#10;print(classification_report(y_test, y_pred, digits=3))&#10;print(f'ROC AUC Score: {roc_auc_score(y_test, y_proba):.3f}')&#10;&#10;#%%&#10;# Step 6: Train and evaluate a Neural Network for fraud detection&#10;from tensorflow import keras&#10;from tensorflow.keras import layers&#10;from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score&#10;import pandas as pd&#10;&#10;# Load train and test data (in case running this cell independently)&#10;X_train = pd.read_csv('X_train.csv')&#10;X_test = pd.read_csv('X_test.csv')&#10;y_train = pd.read_csv('y_train.csv').values.ravel()&#10;y_test = pd.read_csv('y_test.csv').values.ravel()&#10;&#10;# Build a simple neural network model&#10;nn_model = keras.Sequential([&#10;    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),&#10;    layers.Dense(8, activation='relu'),&#10;    layers.Dense(1, activation='sigmoid')&#10;])&#10;nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])&#10;&#10;# Train the model&#10;nn_model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=1, validation_split=0.1)&#10;&#10;# Predict on test set&#10;y_pred_nn = (nn_model.predict(X_test) &gt; 0.5).astype(int).ravel()&#10;y_proba_nn = nn_model.predict(X_test).ravel()&#10;&#10;# Evaluation&#10;print('Confusion Matrix (Neural Network):')&#10;print(confusion_matrix(y_test, y_pred_nn))&#10;print('\nClassification Report (Neural Network):')&#10;print(classification_report(y_test, y_pred_nn, digits=3))&#10;print(f'ROC AUC Score (Neural Network): {roc_auc_score(y_test, y_proba_nn):.3f}')" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/requirements.txt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/requirements.txt" />
              <option name="originalContent" value="numpy&#10;pandas&#10;tensorflow&#10;fastapi&#10;uvicorn&#10;matplotlib&#10;" />
              <option name="updatedContent" value="numpy&#10;pandas&#10;tensorflow&#10;fastapi&#10;uvicorn&#10;matplotlib&#10;scikit-learn" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/simple_explanation.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/simple_explanation.py" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/simple_neural_network.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/simple_neural_network.py" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/train_example.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/train_example.py" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/xor_api/main.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/xor_api/main.py" />
              <option name="originalContent" value="from fastapi import FastAPI, HTTPException, Query&#10;from pydantic import BaseModel, conlist&#10;import numpy as np&#10;from tensorflow import keras&#10;import os&#10;&#10;# Load the trained model once at startup&#10;MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'xor_model.keras')&#10;model = keras.models.load_model(MODEL_PATH)&#10;&#10;app = FastAPI()&#10;&#10;class InputData(BaseModel):&#10;    data: conlist(float, min_items=2, max_items=2)&#10;&#10;@app.get(&quot;/predict&quot;)&#10;def predict(&#10;    x1: float = Query(..., ge=0.0, le=1.0, description=&quot;First input in [0, 1]&quot;),&#10;    x2: float = Query(..., ge=0.0, le=1.0, description=&quot;Second input in [0, 1]&quot;)&#10;):&#10;    x = np.array([[x1, x2]])&#10;    prediction = model.predict(x)&#10;    return {&quot;prediction&quot;: float(prediction[0][0])}&#10;" />
              <option name="updatedContent" value="from fastapi import FastAPI, HTTPException, Query&#10;import numpy as np&#10;from tensorflow import keras&#10;import os&#10;&#10;# Load the trained model once at startup&#10;MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'xor_model.keras')&#10;model = keras.models.load_model(MODEL_PATH)&#10;&#10;app = FastAPI()&#10;&#10;@app.get(&quot;/predict&quot;)&#10;def predict(&#10;    x1: float = Query(..., ge=0.0, le=1.0, description=&quot;First input in [0, 1]&quot;),&#10;    x2: float = Query(..., ge=0.0, le=1.0, description=&quot;Second input in [0, 1]&quot;)&#10;):&#10;    x = np.array([[x1, x2]])&#10;    prediction = model.predict(x)&#10;    return {&quot;prediction&quot;: float(prediction[0][0])}" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>